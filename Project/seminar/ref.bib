
@article{grondin_manyears_2013,
	title = {The {ManyEars} open framework},
	url = {http://link.springer.com/article/10.1007/s10514-012-9316-x},
	urldate = {2013-04-18},
	journal = {Autonomous Robots},
	author = {Grondin, Fran{\textbackslash}ccois and Létourneau, Dominic and Ferland, Fran{\textbackslash}ccois and Rousseau, Vincent and Michaud, Fran{\textbackslash}ccois},
	year = {2013},
	pages = {1–16},
	file = {10.1007s10514-012-9316-x.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/EU2TSRW5/10.1007s10514-012-9316-x.pdf:application/pdf}
},

@article{fritz_auditory_2007,
	title = {Auditory attention — focusing the searchlight on sound},
	volume = {17},
	issn = {0959-4388},
	shorttitle = {Sensory systems},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438807000943},
	doi = {10.1016/j.conb.2007.07.011},
	abstract = {Some fifty years after the first physiological studies of auditory attention, the field is now ripening, with exciting recent insights into the psychophysics, psychology, and neural basis of auditory attention. Current research seeks to unravel the complex interactions of pre-attentive and attentive processing of the acoustic scene, the role of auditory attention in mediating receptive-field plasticity in both auditory spatial and auditory feature processing, the contrasts and parallels between auditory and visual attention pathways and mechanisms, the interplay of bottom-up and top-down attentional mechanisms, the influential role of attention, goals, and expectations in shaping auditory processing, and the orchestration of diverse attentional effects at multiple levels from the cochlea to the cortex.},
	number = {4},
	urldate = {2013-06-05},
	journal = {Current Opinion in Neurobiology},
	author = {Fritz, Jonathan B and Elhilali, Mounya and David, Stephen V and Shamma, Shihab A},
	year = {2007},
	note = {Cited by 0132},
	pages = {437--455},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/X29XQAEX/Fritz et al. - 2007 - Auditory attention — focusing the searchlight on s.pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/753TEW6T/S0959438807000943.html:text/html}
},

@article{cherry_experiments_1953,
	title = {Some Experiments on the Recognition of Speech, with One and with Two Ears},
	volume = {25},
	copyright = {© 1953 Acoustical Society of America},
	url = {http://link.aip.org/link/?JAS/25/975/1},
	doi = {10.1121/1.1907229},
	abstract = {This paper describes a number of objective experiments on recognition, concerning particularly the relation between the messages received by the two ears. Rather than use steady tones or clicks (frequency or time‐point signals) continuous speech is used, and the results interpreted in the main statistically.
Two types of test are reported: (a) the behavior of a listener when presented with two speech signals simultaneously (statistical filtering problem) and (b) behavior when different speech signals are presented to his two ears.},
	number = {5},
	urldate = {2013-06-05},
	journal = {The Journal of the Acoustical Society of America},
	author = {Cherry, E. Colin},
	year = {1953},
	note = {Cited by 2426},
	pages = {975--979},
	file = {Cherry53-cpe.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/KNDIITAB/Cherry53-cpe.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/6ZGCG46U/p975_s1.html:text/html}
},

@article{huang_model-based_1999,
	title = {A model-based sound localization system and its application to robot navigation},
	volume = {27},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889099000020},
	doi = {10.1016/S0921-8890(99)00002-0},
	abstract = {This paper describes a mobile robot equipped with a real time sound localization system as well as a sonar system for obstacle detection. The sound localization method is based on a model of the precedence effect of the human auditory system to cope with echoes and reverberations. Sound localization and robot navigation experiments were conducted. The results show that the robot is capable of localizing sounding objects in a reverberant environment and approaching the objects without collisions, even when the objects were behind obstacles. Environment flexibility and error robustness of the system were discussed as well.},
	number = {4},
	urldate = {2013-06-05},
	journal = {Robotics and Autonomous Systems},
	author = {Huang, Jie and Supaongprapa, Tadawute and Terakura, Ikutaka and Wang, Fuming and Ohnishi, Noboru and Sugie, Noboru},
	year = {1999},
	note = {Cited by 0099},
	keywords = {Model of the precedence effect, Robot audition, Robot navigation, Sound localization},
	pages = {199--209},
	file = {ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/HCJ38MGZ/S0921889099000020.html:text/html}
},

@inproceedings{murray_robotics_2004,
	title = {Robotics sound-source localization and tracking using interaural time difference and crosscorrelation},
	url = {http://www.ent.mrt.ac.lk/~rohan/teaching/EN5101/Reading/murray_ulm04.pdf},
	urldate = {2013-06-05},
	booktitle = {Proceedings of {NeuroBotics} Workshop},
	author = {Murray, John C. and Erwin, Harry and Wermter, Stefan},
	year = {2004},
	note = {Cited by 0033},
	pages = {89–97},
	file = {download;jsessionid=C009638B8A7714E95FE3F16F1D5D66BB.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/IVPZMIFF/download;jsessionid=C009638B8A7714E95FE3F16F1D5D66BB.pdf:application/pdf}
},

@article{huang_building_1997,
	title = {Building ears for robots: Sound localization and separation},
	volume = {1},
	issn = {1433-5298, 1614-7456},
	shorttitle = {Building ears for robots},
	url = {http://link.springer.com/article/10.1007/BF02471133},
	doi = {10.1007/BF02471133},
	abstract = {This paper describes our research on bio-mimetic robot audition. Among the many binaural and monaural sound localization cues in the human auditory system, the interaural time difference cue is selected as it can easily be obtained by omnidirectional microphones. We have used a three-microphone system to remove the anterior-posterior ambiguity which occurs in two-microphone (or ear) systems. The echo-avoidance model of the precedence effect is used to cope with the echoes and reverberations of real environments. We mimicked the cocktail party effect by perceptual grouping of continuous components according to the spatial information obtained by the sound localization method. A wheel-based mobile robot equipped with an auditory system was developed. The auditory system has two sound processing parts. One is a {DSP-based} realtime system; the other is an off-line system composed of remote computers. Experiments of localizing and separating multiple sound sources and robot navigation were conducted to demonstrate the system's ability and potential applications.},
	language = {en},
	number = {4},
	urldate = {2013-06-05},
	journal = {Artificial Life and Robotics},
	author = {Huang, Jie and Ohnishi, Noboru and Sugie, Noboru},
	month = dec,
	year = {1997},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Cocktail party effect, Computation by Abstract Devices, Precedence effect, Robot audition, Robot navigation, Sound localization},
	pages = {157--163},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/XB566VHB/Huang et al. - 1997 - Building ears for robots Sound localization and s.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/JAD7HTQB/BF02471133.html:text/html}
},

@inproceedings{valin_robust_2006,
	title = {Robust {3D} Localization and Tracking of Sound Sources Using Beamforming and Particle Filtering},
	volume = {4},
	doi = {10.1109/ICASSP.2006.1661100},
	abstract = {In this paper we present a new robust sound source localization and tracking method using an array of eight microphones ({US} patent pending). The method uses a steered beamformer based on the reliability-weighted phase transform ({RWPHAT)} along with a particle filter-based tracking algorithm. The proposed system is able to estimate both the direction and the distance of the sources. In a videoconferencing context, the direction was estimated with an accuracy better than one degree while the distance was accurate within 10\% {RMS.} Tracking of up to three simultaneous moving speakers is demonstrated in a noisy environment},
	booktitle = {2006 {IEEE} International Conference on Acoustics, Speech and Signal Processing, 2006. {ICASSP} 2006 Proceedings},
	author = {Valin, J.-M. and Michaud, F. and Rouat, Jean},
	year = {2006},
	keywords = {{3D} sound source localization, {3D} sound source tracking, Array signal processing, audio signal processing, beamforming, Cameras, Delay, Filtering, Frequency domain analysis, microphone array, microphone arrays, particle filtering, particle filtering (numerical methods), Particle filters, Particle tracking, reliability-weighted phase transform, Robustness, steered beamformer, teleconferencing, transforms, videoconferencing},
	pages = {IV--IV},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/9B2I2P8D/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/TP43348T/Valin et al. - 2006 - Robust 3D Localization and Tracking of Sound Sourc.pdf:application/pdf}
},

@inproceedings{otsuka_bayesian_2012,
	title = {Bayesian Unification of Sound Source Localization and Separation with Permutation Resolution},
	url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewPDFInterstitial/4911/5369},
	urldate = {2013-06-05},
	booktitle = {Proc. of {AAAI} Conf. on Artificial Intelligence},
	author = {Otsuka, Takuma and Ishiguro, Katsuhiko and Sawada, Hiroshi and Okuno, Hiroshi G.},
	year = {2012},
	pages = {2038–2045},
	file = {5369.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/FZK5Z77J/5369.pdf:application/pdf}
},

@incollection{de_cheveigne_computational_2010,
	title = {Computational Auditory Scene Analysis},
	copyright = {Copyright © 2009 {ISTE} Ltd.},
	isbn = {9780470611180},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470611180.ch5/summary},
	abstract = {This chapter contains sections titled: * Introduction * Principles of auditory scene analysis * {CASA} principles * Critique of the {CASA} approach * Perspectives * References},
	language = {en},
	urldate = {2013-06-05},
	booktitle = {Spoken Language Processing},
	publisher = {{ISTE}},
	author = {De Cheveigné, Alain},
	editor = {Josephriani},
	year = {2010},
	note = {Cited by 0000},
	keywords = {description, experimentations, practical problems, psychoacousticians, segregation},
	pages = {189–211},
	file = {Snapshot:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/TG6VCVPX/summary.html:text/html}
},

@inproceedings{beh_sound_2010,
	title = {Sound source separation by using matched beamforming and time-frequency masking},
	doi = {10.1109/IROS.2010.5652512},
	abstract = {This paper proposes a two-stage algorithm to separate two sound sources by using matched beamforming and time-frequency masking techniques. At first, beamforming was used to separate the sound mixtures back to the original sources while preserving the original contents to the maximum extent. The residual interference was then suppressed by the time-frequency masking technique. A sequential least squares method was used in developing a matched beamformer to estimate the relative transfer function ({RTF).} From experimental results, it has been shown that the proposed method exhibits improved performance in sound source separation compared to conventional methods. Signal enhanced factor ({SEF)} was improved by an average of 8.39 {dB} over the baseline.},
	booktitle = {2010 {IEEE/RSJ} International Conference on Intelligent Robots and Systems ({IROS)}},
	author = {Beh, Jounghoon and Lee, Taekjin and Han, D. and Ko, Hanseok},
	year = {2010},
	note = {Cited by 0002},
	keywords = {Array signal processing, human-robot interaction, independent component analysis, least squares approximations, matched beamforming technique, relative transfer function, residual interference, sequential least squares method, signal enhanced factor, sound source separation, source separation, speech based human-robot interface, speech processing, time-frequency masking technique},
	pages = {458--463},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/64SC2UJC/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/7466CNTE/Beh et al. - 2010 - Sound source separation by using matched beamformi.pdf:application/pdf}
},

@article{gunel_acoustic_2008,
	title = {Acoustic source separation of convolutive mixtures based on intensity vector statistics},
	volume = {16},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4457927},
	number = {4},
	urldate = {2013-06-05},
	journal = {Audio, Speech, and Language Processing, {IEEE} Transactions on},
	author = {Gunel, B. and Hachabiboglu, H. and Kondoz, Ahmet M.},
	year = {2008},
	note = {Cited by 0017},
	pages = {748–756},
	file = {gunhhokon_IEEETSALP08.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/QD63TCCV/gunhhokon_IEEETSALP08.pdf:application/pdf}
},

@article{gunel_acoustic_2008-1,
	title = {Acoustic source separation of convolutive mixtures based on intensity vector statistics},
	volume = {16},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4457927},
	number = {4},
	urldate = {2013-06-05},
	journal = {Audio, Speech, and Language Processing, {IEEE} Transactions on},
	author = {Gunel, B. and Hachabiboglu, H. and Kondoz, Ahmet M.},
	year = {2008},
	note = {Cited by 0017},
	pages = {748–756},
	file = {gunhhokon_IEEETSALP08.pdf:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/MNBWAX7I/gunhhokon_IEEETSALP08.pdf:application/pdf}
},

@inproceedings{valin_robust_2003,
	title = {Robust sound source localization using a microphone array on a mobile robot},
	volume = {2},
	doi = {10.1109/IROS.2003.1248813},
	abstract = {The hearing sense on a mobile robot is important because it is omnidirectional and it does not require direct line-of-sight with the sound source. Such capabilities can nicely complement vision to help localize a person or an interesting event in the environment. To do so the robot auditory system must be able to work in noisy, unknown and diverse environmental conditions. In this paper, we present a robust sound source localization method in three-dimensional space using an array of 8 microphones. The method is based on time delay of arrival estimation. Results show that a mobile robot can localize in real time different types of sound sources over a range of 3 meters and with a precision of 3°.},
	booktitle = {2003 {IEEE/RSJ} International Conference on Intelligent Robots and Systems, 2003. ({IROS} 2003). Proceedings},
	author = {Valin, J.-M. and Michaud, F. and Rouat, J. and Letourneau, D.},
	year = {2003},
	keywords = {Acoustic noise, acoustic signal processing, Array signal processing, Auditory system, Delay effects, Delay estimation, direction-of-arrival estimation, direct line-of-sight, microphone array, microphone arrays, microphones, mobile robot, mobile robots, noise, Orbital robotics, robot auditory system, Robot sensing systems, Robustness, robust sound source localization, robust sound source localization method, three-dimensional space, Working environment noise},
	pages = {1228--1233 vol.2},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/8scdd80y.default/zotero/storage/8TGVD27H/login.html:text/html}
}